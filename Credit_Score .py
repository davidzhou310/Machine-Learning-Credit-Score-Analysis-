# -*- coding: utf-8 -*-
"""cis5200_final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lbsA6clqgXehPVodpqq5H7-aGIHR-DDy

# Data Clearning and Analysis
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, auc
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler


from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC, LinearSVC

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier

drive.mount('/content/drive/', force_remount=True)
source_data = pd.read_csv('train.csv')

source_data.head(10)

#check invalid Nan values
source_data.isnull().sum()

#Check data type
source_data.info()

#drop unuseful data
source_data.drop(['ID','Customer_ID','SSN','Name'], axis = 1, inplace = True)

#data after drop
source_data.info()

#check distribution of credit score
plt.figure(figsize=(6,6))
sns.countplot(x = 'Credit_Score', data = source_data)

#number of credit scores
source_data['Credit_Score'].value_counts()

"""Data is moderate imbalance, we need to use some methods to sampleing data instead of random sampleing"""

#correlation


plt.figure(figsize=(10,10))
sns.heatmap(source_data.corr())
#most of numerical data are not strong correlated.

numCols = source_data.select_dtypes([np.number]).columns
for col in numCols:
    fig, ax =plt.subplots(1,2, figsize=(12,8))
    sns.boxplot(data=source_data, y=col, ax=ax[0])
    sns.displot(x=col,data=source_data, hue='Credit_Score')
    plt.show()

"""Although there are some outliers in categories such as monthly balance,amount invested monthly etc., overall there is no nonsense data and the distributions of these data over credit score is acceptable."""

#analysis categorical data to numerical
categorical = source_data.loc[:, source_data.dtypes==np.object]
categorical.columns

for col in categorical:
  print(categorical[col].value_counts())

"""We can see that Type of Loan is description text about loans the customer holds. Meanwhile, large amount of the data is not specified. We decide to drop this feature.

Numerical all categorical data
"""

#encode data and drop type_of_loan
source_data.drop(['Type_of_Loan'], axis=1, inplace = True)
df = source_data.copy()
categorical.drop(['Type_of_Loan'], axis=1, inplace = True)
for col in categorical:
  encoded = pd.get_dummies(df[col], prefix = col)
  df = pd.concat([df, encoded], axis = 1)
  df.drop([col], axis = 1, inplace = True)

df.head(10)

df.info()

"""Numerical credit score which is our y"""

#modify credit score to single column
#use label encoding
credit_score_le = LabelEncoder()
df['Credit_Score'] = credit_score_le.fit_transform(source_data['Credit_Score'])
df.drop(['Credit_Score_Good','Credit_Score_Poor','Credit_Score_Standard'], axis= 1, inplace = True)

df.head(10)

"""0 represent good, 2 represent standard, 1 represent poor"""

plt.figure(figsize=(20,20))
sns.heatmap(df.corr())

"""# Feature Selection"""

X = df.drop(['Credit_Score'], axis = 1)
Y = df['Credit_Score']
X.info()



from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators = 400)
model.fit(X,Y)
importance = model.feature_importances_

imp = pd.DataFrame(data = importance*100, columns = ['Importance'], index = X.columns)
imp = imp.sort_values('Importance')
imp.plot.bar()

imp.plot(kind='barh')
imp

"""We can see that all occupations and payment behaviours are not important in our random forest model. Therefore, we choose to drop all these features.

There is no significant important feature and because of the size of features, we choose to use all features.
"""

X.columns

X.drop(['Occupation_Accountant', 'Occupation_Architect',
       'Occupation_Developer', 'Occupation_Doctor', 'Occupation_Engineer',
       'Occupation_Entrepreneur', 'Occupation_Journalist', 'Occupation_Lawyer',
       'Occupation_Manager', 'Occupation_Mechanic', 'Occupation_Media_Manager',
       'Occupation_Musician', 'Occupation_Scientist', 'Occupation_Teacher',
       'Occupation_Writer','Payment_Behaviour_High_spent_Large_value_payments',
       'Payment_Behaviour_High_spent_Medium_value_payments',
       'Payment_Behaviour_High_spent_Small_value_payments',
       'Payment_Behaviour_Low_spent_Large_value_payments',
       'Payment_Behaviour_Low_spent_Medium_value_payments',
       'Payment_Behaviour_Low_spent_Small_value_payments'], axis = 1, inplace=True)

X.head(10)

"""# Sampling data and Model implementation

Try three sampling methods on base line model.
Oversample, undersample, SMOTE
"""

from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import VotingClassifier

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)

"""Baseline model Logistic regression, do rebalance test on baseline model

*   Use F1 score as evaluation metric because of imbalance


"""

rebalancer = [RandomUnderSampler(random_state=0),RandomOverSampler(random_state=0), SMOTE()]
rebal_name = ['Undersampler', 'OverSampler', 'SMOTE']

logit = LogisticRegression(max_iter=1000)
clf = logit.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print('Unbalanced')
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))

for index, sampler in enumerate(rebalancer):
    X_train_balanced, y_train_balanced = sampler.fit_resample(X_train, y_train)
    clf_balanced = logit.fit(X_train_balanced, y_train_balanced)
    y_pred_bal = clf_balanced.predict(X_test)
    print(rebal_name[index])
    print(classification_report(y_test,y_pred_bal))
    print(accuracy_score(y_test, y_pred))

#rebalance_comp(rebalancer)
#accus, accu_balanceds = np.round(rebalance_comp(rebalancer), 3)

'''acc_table = pd.DataFrame({"Balancing Method": ['Undersample', 'Oversample','SMOTE'], 
                      "Accuracy (imbalanced)": accus, 
                      "Accuracy (balanced)": accu_balanceds})

pd.pivot_table(acc_table, index=['Balancing Method']).sort_values(by="Accuracy (balanced)", ascending=False)'''

"""## Tuning models

Decision Tree(no need to tune, this is final training model)
"""

dt = DecisionTreeClassifier(max_depth=12)
ddt_clf = dt.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print('Unbalanced')
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))

for index, sampler in enumerate(rebalancer):
    X_train_balanced, y_train_balanced = sampler.fit_resample(X_train, y_train)
    clf_balanced = dt.fit(X_train_balanced, y_train_balanced)
    y_pred_bal = clf_balanced.predict(X_test)
    print(rebal_name[index])
    print(classification_report(y_test,y_pred_bal))
    print(accuracy_score(y_test, y_pred_bal))

"""Randome forest kfold tuning"""

rf_par= {'n_estimators': [100, 200, 400, 800],
           'max_features': ['auto', 'sqrt', 'log2'],
           'min_samples_split': [2, 5, 10, 20]}

rf = RandomForestClassifier()
rf_cv = GridSearchCV(rf, rf_par, cv=10, n_jobs=-1, verbose=2)
rf_cv.fit(X_train[:5000], y_train[:5000])
print("Best paramters combination of Random Forest: {}".format(rf_cv.best_params_))

"""Don't use svm since tuning time too long(more than 10 hours).

Neural Network Tuning
"""

nn_par = {'alpha': [1, 0.1, 0.01, 0.001],
           'hidden_layer_sizes': [(48,48,48), (120,120)],
           'solver': ["adam", "sgd"],
           'activation': ["logistic", "relu"]}

nn = MLPClassifier()
nn_cv = GridSearchCV(nn, nn_par, cv=10, n_jobs=-1, verbose=2)
nn_cv.fit(X_train[:5000], y_train[:5000])
print("Best paramters combination of Neural Network: {}".format(nn_cv.best_params_))

"""XGBoost, Adaboost, soft voting

## Implement models

Decision Tree has been implemented above

XGBoost
"""

xgb = XGBClassifier()
xgb_clf = xgb.fit(X_train, y_train)
X_test_bal, y_test_bal= SMOTE().fit_resample(X_test, y_test)
y_pred = xgb.predict(X_test_bal)
print('Unbalanced')
print(classification_report(y_test_bal, y_pred))
print(accuracy_score(y_test_bal, y_pred))
for index, sampler in enumerate(rebalancer):
    X_train_balanced, y_train_balanced = sampler.fit_resample(X_train, y_train)
    clf_balanced = xgb.fit(X_train_balanced, y_train_balanced)
    y_pred_bal = clf_balanced.predict(X_test_bal)
    print(rebal_name[index])
    print(classification_report(y_test_bal,y_pred_bal))
    print(accuracy_score(y_test_bal, y_pred_bal))

"""ADAboost"""

ada = AdaBoostClassifier(n_estimators = 800)
ada_clf = ada.fit(X_train, y_train)
y_pred = ada.predict(X_test)
print('Unbalanced')
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))
for index, sampler in enumerate(rebalancer):
    X_train_balanced, y_train_balanced = sampler.fit_resample(X_train, y_train)
    clf_balanced = ada.fit(X_train_balanced, y_train_balanced)
    y_pred_bal = clf_balanced.predict(X_test)
    print(rebal_name[index])
    print(classification_report(y_test,y_pred_bal))
    print(accuracy_score(y_test, y_pred_bal))

"""Random forest"""

rf = RandomForestClassifier(max_features='sqrt', min_samples_split=2, n_estimators=200)
rf_clf = rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
print('Unbalanced')
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))
for index, sampler in enumerate(rebalancer):
    X_train_balanced, y_train_balanced = sampler.fit_resample(X_train, y_train)
    clf_balanced = rf.fit(X_train_balanced, y_train_balanced)
    y_pred_bal = clf_balanced.predict(X_test)
    print(rebal_name[index])
    print(classification_report(y_test,y_pred_bal))
    print(accuracy_score(y_test, y_pred_bal))

"""Neural Network"""

#standardlize
scaler = StandardScaler()
scaler.fit(X_train)
X_train_standard = scaler.transform(X_train)
X_test_standard = scaler.transform(X_test)
nn = MLPClassifier(alpha=0.01, hidden_layer_sizes=(48,48,48), activation = 'logistic', solver = 'adam')
nn_clf = nn.fit(X_train_standard, y_train)
y_pred = nn.predict(X_test_standard)
print('Unbalanced')
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))
for index, sampler in enumerate(rebalancer):
    X_train_balanced, y_train_balanced = sampler.fit_resample(X_train, y_train)
    X_train_standard_b = scaler.transform(X_train_balanced)
    clf_balanced = nn.fit(X_train_standard_b, y_train_balanced)
    y_pred_bal = clf_balanced.predict(X_test_standard)
    print(rebal_name[index])
    print(classification_report(y_test,y_pred_bal))
    print(accuracy_score(y_test, y_pred_bal))

"""Soft voting"""

sv = VotingClassifier(estimators=[('DT', ddt_clf), ('XGboost',xgb_clf),('RandomF',rf_clf),('NeuralN',nn_clf)], voting='soft',weights=[1,1,2,2])
sv_clf = sv.fit(X_train, y_train)
y_pred = sv_clf.predict(X_test)
print('Unbalanced')
print(classification_report(y_test, y_pred))
print(accuracy_score(y_test, y_pred))